{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from google.cloud import storage\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "PROJECT_ID = \"nbaproject-469714\"\n",
    "BUCKET_NAME = \"nba_bucket_datasets\"\n",
    "LOCAL_CSV_FOLDER = r\"D:\\Up\\New\\Estudios\\SoyHenry\\Data Analytics\\ProyectoFinal\\csv\"\n",
    "LOG_FILE = \"upload_log.txt\"\n",
    "METADATA_FILE = \"bucket_file_metadata.json\"\n",
    "\n",
    "AUTOMATIC_SOURCES = [\n",
    "    {\"type\": \"api\", \"url\": \"https://api-nba.com/stats.csv\"},\n",
    "    {\"type\": \"gsheet\", \"url\": \"https://docs.google.com/spreadsheets/d/xxxx/export?format=csv\"}\n",
    "]\n",
    "\n",
    "# Cargar metadatos anteriores\n",
    "if os.path.exists(METADATA_FILE):\n",
    "    with open(METADATA_FILE, \"r\") as f:\n",
    "        bucket_metadata = json.load(f)\n",
    "else:\n",
    "    bucket_metadata = {}\n",
    "\n",
    "def log_message(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(message)\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(f\"{timestamp} - {message}\\n\")\n",
    "\n",
    "def file_hash(path):\n",
    "    h = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def upload_to_bucket(bucket_name, destination_blob_name, source_file):\n",
    "    client = storage.Client(PROJECT_ID)\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    local_hash = file_hash(source_file)\n",
    "\n",
    "    # Verificar cambios con metadatos\n",
    "    previous_hash = bucket_metadata.get(destination_blob_name)\n",
    "    if previous_hash == local_hash:\n",
    "        log_message(f\"‚ö†Ô∏è {destination_blob_name} ya existe y no cambi√≥, se omitir√°\")\n",
    "        return False\n",
    "\n",
    "    blob.upload_from_filename(source_file)\n",
    "    log_message(f\"‚úÖ {source_file} subido a gs://{bucket_name}/{destination_blob_name}\")\n",
    "\n",
    "    # Actualizar metadatos\n",
    "    bucket_metadata[destination_blob_name] = local_hash\n",
    "    with open(METADATA_FILE, \"w\") as f:\n",
    "        json.dump(bucket_metadata, f)\n",
    "\n",
    "    return True\n",
    "\n",
    "def process_csv_file(path):\n",
    "    file_name = os.path.basename(path)\n",
    "    return upload_to_bucket(BUCKET_NAME, file_name, path)\n",
    "\n",
    "def process_api(url):\n",
    "    local_file = \"temp_api_data.csv\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        with open(local_file, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        return upload_to_bucket(BUCKET_NAME, local_file, local_file)\n",
    "    except Exception as e:\n",
    "        log_message(f\"‚ö†Ô∏è Error al descargar API {url}: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if os.path.exists(local_file):\n",
    "            os.remove(local_file)\n",
    "\n",
    "def process_gsheet(sheet_url):\n",
    "    local_file = \"temp_gsheet_data.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(sheet_url)\n",
    "        df.to_csv(local_file, index=False)\n",
    "        return upload_to_bucket(BUCKET_NAME, local_file, local_file)\n",
    "    except Exception as e:\n",
    "        log_message(f\"‚ö†Ô∏è Error al descargar Google Sheet {sheet_url}: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        if os.path.exists(local_file):\n",
    "            os.remove(local_file)\n",
    "\n",
    "def main():\n",
    "    # üîπ CSV locales\n",
    "    for csv_file in glob.glob(os.path.join(LOCAL_CSV_FOLDER, \"*.csv\")):\n",
    "        process_csv_file(csv_file)\n",
    "\n",
    "    # üîπ APIs y Google Sheets\n",
    "    for source in AUTOMATIC_SOURCES:\n",
    "        if source[\"type\"] == \"api\":\n",
    "            process_api(source[\"url\"])\n",
    "        elif source[\"type\"] == \"gsheet\":\n",
    "            process_gsheet(source[\"url\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analista",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
